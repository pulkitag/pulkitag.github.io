---
layout: default
title: Interpreting Machine Learning Models
---

# Weights of a linear model are not informative of feature importance

This is very surprising to hear at first, but it is true.
See Figure 1/Example 2 in the [paper](http://www.sciencedirect.com/science/article/pii/S1053811913010914)
